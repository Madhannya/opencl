{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenCL_with_Python.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zRoLHnNtw53",
        "colab_type": "text"
      },
      "source": [
        "#0. Install PyOpenCL library\n",
        "We need to install the library first. Also, if you run the code and it shows \"Can't find library\", then you need to rerun this step. Google Colab will delete every library installation everytime the runtime reset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwLixFOVYFno",
        "colab_type": "code",
        "outputId": "7a798410-a6a7-4a27-d3d4-9d96073f1ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "!pip install pyopencl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyopencl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/5e/877a5f129473160217a15e8aa9dbd3195f36fd10ef06e6f5ee3631ed454e/pyopencl-2019.1.2-cp36-cp36m-manylinux1_x86_64.whl (725kB)\n",
            "\r\u001b[K     |▌                               | 10kB 27.4MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 71kB 4.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 81kB 4.6MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |████▌                           | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 471kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 481kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 491kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 501kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 512kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 522kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 532kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 542kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 552kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 563kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 573kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 583kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 593kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 604kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 614kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 624kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 634kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 645kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 655kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 665kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 675kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 686kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 696kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 706kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 716kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 727kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pyopencl) (1.12.0)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pyopencl) (4.4.2)\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Collecting pytools>=2017.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/c7/88a4f8b6f0f78d0115ec3320861a0cc1f6daa3b67e97c3c2842c33f9c089/pytools-2020.1.tar.gz (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyopencl) (1.18.2)\n",
            "Building wheels for collected packages: pytools\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2020.1-py2.py3-none-any.whl size=59602 sha256=7bcedb5a10ed6ebbed8205cc8e3567db1d57e732911626ebf0f0b23a34253302\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/da/1b/946775a88291378182ed92c9800d6d0ebc2a554cb89829cc24\n",
            "Successfully built pytools\n",
            "Installing collected packages: appdirs, pytools, pyopencl\n",
            "Successfully installed appdirs-1.4.3 pyopencl-2019.1.2 pytools-2020.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PebEXKLCuKE-",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup Runtime\n",
        "At the \"Runtime\" menu, choose \"change runtime type\". Then, make sure that you choose \"Python 3\" as runtime type, and \"GPU\" as hardware accelerator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuv1eO9-v6Lr",
        "colab_type": "text"
      },
      "source": [
        "# 2. Check if OpenCL can run correctly\n",
        "Run code in the following cell, it should show the information about platform(s) and device(s) on the current runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVSkYM2eYzii",
        "colab_type": "code",
        "outputId": "6f909890-88d0-4d75-9262-a127c289266c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "import pyopencl as cl\n",
        "platforms = cl.get_platforms()\n",
        "platform_count = 0\n",
        "for platform in platforms:\n",
        "  print('Platform #', platform_count)\n",
        "  print('\\tVendor:', platform.get_info(cl.platform_info.VENDOR))\n",
        "  print('\\tName:', platform.get_info(cl.platform_info.NAME))\n",
        "  print('\\tProfile:', platform.get_info(cl.platform_info.PROFILE))\n",
        "  devices = platform.get_devices(cl.device_type.ALL)\n",
        "  device_count = 0\n",
        "  for device in devices:\n",
        "    print('\\tDevice #', device_count)\n",
        "    print('\\t\\tVendor', device.get_info(cl.device_info.VENDOR))\n",
        "    print('\\t\\tName', device.get_info(cl.device_info.NAME))\n",
        "    print('\\t\\tMax Compute Units', device.get_info(cl.device_info.MAX_COMPUTE_UNITS))\n",
        "    print('\\t\\tMax Clock Frequency', device.get_info(cl.device_info.MAX_CLOCK_FREQUENCY))\n",
        "    print('\\t\\tGlobal Mem Size', device.get_info(cl.device_info.GLOBAL_MEM_SIZE))\n",
        "    print('\\t\\tLocal Mem Size', device.get_info(cl.device_info.LOCAL_MEM_SIZE))\n",
        "    device_count = device_count + 1\n",
        "  pltform_count = platform_count + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Platform # 0\n",
            "\tVendor: NVIDIA Corporation\n",
            "\tName: NVIDIA CUDA\n",
            "\tProfile: FULL_PROFILE\n",
            "\tDevice # 0\n",
            "\t\tVendor NVIDIA Corporation\n",
            "\t\tName Tesla P4\n",
            "\t\tMax Compute Units 20\n",
            "\t\tMax Clock Frequency 1113\n",
            "\t\tGlobal Mem Size 7981694976\n",
            "\t\tLocal Mem Size 49152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LllAhsscxhJZ",
        "colab_type": "text"
      },
      "source": [
        "# 3. Example OpenCL code\n",
        "This code perform calculating a + b, where a and b are 50,000 random float. The result is in rest_np. Please compare the python's OpenCL functions with C's OpenCL function in the slides. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssCRIB-zZh1I",
        "colab_type": "code",
        "outputId": "129cfcb4-a208-4a83-8dcb-a0f8907e4c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "a_np = np.random.rand(50000).astype(np.float32)\n",
        "b_np = np.random.rand(50000).astype(np.float32)\n",
        "\n",
        "ctx = cl.create_some_context()\n",
        "queue = cl.CommandQueue(ctx)\n",
        "\n",
        "mf = cl.mem_flags\n",
        "a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        "b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
        "\n",
        "prg = cl.Program(ctx, \"\"\"\n",
        "__kernel void sum(\n",
        "    __global const float *a_g, __global const float *b_g, __global float *res_g)\n",
        "{\n",
        "  int gid = get_global_id(0);\n",
        "  res_g[gid] = a_g[gid] + b_g[gid];\n",
        "}\n",
        "\"\"\").build()\n",
        "\n",
        "res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
        "prg.sum(queue, a_np.shape, None, a_g, b_g, res_g)\n",
        "\n",
        "res_np = np.empty_like(a_np)\n",
        "cl.enqueue_copy(queue, res_np, res_g)\n",
        "\n",
        "# Check on CPU with Numpy:\n",
        "print('Calculate result = a + b')\n",
        "print('a:', a_np)\n",
        "print('b:', b_np)\n",
        "print('result:', res_np)\n",
        "print('Check the result (result - (a + b):', res_np - (a_np + b_np))\n",
        "print('Find vector norm of the the previous step:', np.linalg.norm(res_np - (a_np + b_np)))\n",
        "assert np.allclose(res_np, a_np + b_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculate result = a + b\n",
            "a: [0.7442459  0.92191094 0.31668732 ... 0.64450383 0.6854204  0.95351774]\n",
            "b: [0.2560115  0.3531105  0.7055     ... 0.42537183 0.8089764  0.5197493 ]\n",
            "result: [1.0002574 1.2750214 1.0221874 ... 1.0698757 1.4943968 1.4732671]\n",
            "Check the result (result - (a + b): [0. 0. 0. ... 0. 0. 0.]\n",
            "Find vector norm of the the previous step: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkvLgtc1x6-l",
        "colab_type": "text"
      },
      "source": [
        "# 4. Is it really faster?\n",
        "Let's measure the execution time. We will use python's time function, it's not accurate but shold be enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jWZ8FyEzx4le",
        "outputId": "88d69388-57f4-4d0a-b94e-1ee205436a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "import time\n",
        "a_np = np.random.rand(50000).astype(np.float32)\n",
        "b_np = np.random.rand(50000).astype(np.float32)\n",
        "\n",
        "def perform_sequential_addition(a_np, b_np):\n",
        "  result = np.empty_like(a_np)\n",
        "  size = a_np.size\n",
        "  for x in range(0, size):\n",
        "    result[x] = a_np[x] + b_np[x]\n",
        "  return result\n",
        "\n",
        "def perform_opencl_addition(a_np, b_np):\n",
        "  ctx = cl.create_some_context()\n",
        "  queue = cl.CommandQueue(ctx)\n",
        "\n",
        "  mf = cl.mem_flags\n",
        "  a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        "  b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
        "\n",
        "  prg = cl.Program(ctx, \"\"\"\n",
        "  __kernel void sum(\n",
        "      __global const float *a_g, __global const float *b_g, __global float *res_g)\n",
        "  {\n",
        "    int gid = get_global_id(0);\n",
        "    res_g[gid] = a_g[gid] + b_g[gid];\n",
        "  }\n",
        "  \"\"\").build()\n",
        "\n",
        "  res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
        "  prg.sum(queue, a_np.shape, None, a_g, b_g, res_g)\n",
        "\n",
        "  res_np = np.empty_like(a_np)\n",
        "  cl.enqueue_copy(queue, res_np, res_g)\n",
        "  return res_np\n",
        "\n",
        "# Run sequential code\n",
        "start_time = time.time()\n",
        "res_np = perform_sequential_addition(a_np, b_np)\n",
        "end_time = time.time()\n",
        "\n",
        "print('Find vector norm to check result:', np.linalg.norm(res_np - (a_np + b_np)))\n",
        "print(\"Sequential processing time:\", end_time - start_time)\n",
        "\n",
        "# Run parallel code\n",
        "start_time = time.time()\n",
        "res_np = perform_opencl_addition(a_np, b_np)\n",
        "end_time = time.time()\n",
        "\n",
        "print('Find vector norm to check result:', np.linalg.norm(res_np - (a_np + b_np)))\n",
        "print(\"Parallel processing time:\", end_time - start_time)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Find vector norm to check result: 0.0\n",
            "Sequential processing time: 0.02369976043701172\n",
            "Find vector norm to check result: 0.0\n",
            "Parallel processing time: 0.1260664463043213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01hmRUpv0jXq",
        "colab_type": "text"
      },
      "source": [
        "#5. Wait, it seems like sequential code runs faster?\n",
        "That's right, if your data is not big emough, the overhead of transfering data to/from GPU will overrun the parallel performance. So, let's increase the data size and compare again.\n",
        "\n",
        "Note: this is not fair comparison, but for simplicity, this should be OK."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "soS9ZSdp0fiA",
        "outputId": "70dfe6f0-2f22-47db-bb79-81e07ba626bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "import time\n",
        "a_np = np.random.rand(5000000).astype(np.float32)\n",
        "b_np = np.random.rand(5000000).astype(np.float32)\n",
        "\n",
        "def perform_sequential_addition(a_np, b_np):\n",
        "  result = np.empty_like(a_np)\n",
        "  size = a_np.size\n",
        "  for x in range(0, size):\n",
        "    result[x] = a_np[x] + b_np[x]\n",
        "  return result\n",
        "\n",
        "def perform_opencl_addition(a_np, b_np):\n",
        "  ctx = cl.create_some_context()\n",
        "  queue = cl.CommandQueue(ctx)\n",
        "\n",
        "  mf = cl.mem_flags\n",
        "  a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        "  b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
        "\n",
        "  prg = cl.Program(ctx, \"\"\"\n",
        "  __kernel void sum(\n",
        "      __global const float *a_g, __global const float *b_g, __global float *res_g)\n",
        "  {\n",
        "    int gid = get_global_id(0);\n",
        "    res_g[gid] = a_g[gid] + b_g[gid];\n",
        "  }\n",
        "  \"\"\").build()\n",
        "\n",
        "  res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
        "  prg.sum(queue, a_np.shape, None, a_g, b_g, res_g)\n",
        "\n",
        "  res_np = np.empty_like(a_np)\n",
        "  cl.enqueue_copy(queue, res_np, res_g)\n",
        "  return res_np\n",
        "\n",
        "start_time = time.time()\n",
        "res_np = perform_sequential_addition(a_np, b_np)\n",
        "end_time = time.time()\n",
        "sequential_time = end_time - start_time;\n",
        "\n",
        "print('Find vector norm to check result:', np.linalg.norm(res_np - (a_np + b_np)))\n",
        "print(\"Sequential processing time:\", sequential_time)\n",
        "\n",
        "start_time = time.time()\n",
        "res_np = perform_opencl_addition(a_np, b_np)\n",
        "end_time = time.time()\n",
        "parallel_time = end_time - start_time\n",
        "\n",
        "print('Find vector norm to check result:', np.linalg.norm(res_np - (a_np + b_np)))\n",
        "print(\"Parallel processing time:\", parallel_time)\n",
        "\n",
        "print(\"Speed up:\", sequential_time/parallel_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Find vector norm to check result: 0.0\n",
            "Sequential processing time: 2.0483665466308594\n",
            "Find vector norm to check result: 0.0\n",
            "Parallel processing time: 0.1511242389678955\n",
            "Speed up: 13.554189325419927\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZO_g0GnBb32",
        "colab_type": "text"
      },
      "source": [
        "# Question #1\n",
        "So, you can see that parallel code run faster. From the speed up value in the previous step and number of computational core in step 2. Can you guess the ratio of parallel portion? You can answer by edit this cell and put your answer below. Please also show your calculation steps.\n",
        "\n",
        "Answer: from S = 1/1-P then move P to other side P = S-1/S\n",
        "        then S = 13.554 then P = 0.9262 so \n",
        "        the ratio of parallel portion is 92 %  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOnmYanFCVDL",
        "colab_type": "text"
      },
      "source": [
        "# 6. Matrix Multiplication\n",
        "Matrix multiplication is a very common operation on many fields, including simultation, image processing, data analytics. So, in short, we have two matrix, A and B, and we want to find A x B. In sequential code, you will need to have the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05Gdm5hTEHIS",
        "colab_type": "code",
        "outputId": "6fb22681-fc20-41c9-a273-41c642f95bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "import time\n",
        "a_np = np.random.randint(0, high=10, size=[100, 100])\n",
        "b_np = np.random.randint(0, high=10, size=[100, 100])\n",
        "result = np.zeros_like(a_np)\n",
        "for i in range(len(a_np)):\n",
        "  for j in range(len(b_np[0])):\n",
        "    for k in range(len(b_np)):\n",
        "       result[i][j] += a_np[i][k] * b_np[k][j]\n",
        "print(result)\n",
        "print(np.matmul(a_np,b_np))\n",
        "print(np.linalg.norm(result - np.matmul(a_np, b_np)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2074 1823 1926 ... 2136 1999 1891]\n",
            " [2208 1893 2017 ... 2027 1894 2080]\n",
            " [2334 1944 1834 ... 1968 1867 1967]\n",
            " ...\n",
            " [2105 1864 1837 ... 2085 1890 1846]\n",
            " [2412 1960 2270 ... 2213 2040 1981]\n",
            " [2012 1873 1954 ... 2214 1943 1960]]\n",
            "[[2074 1823 1926 ... 2136 1999 1891]\n",
            " [2208 1893 2017 ... 2027 1894 2080]\n",
            " [2334 1944 1834 ... 1968 1867 1967]\n",
            " ...\n",
            " [2105 1864 1837 ... 2085 1890 1846]\n",
            " [2412 1960 2270 ... 2213 2040 1981]\n",
            " [2012 1873 1954 ... 2214 1943 1960]]\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9ukB839Lj8u",
        "colab_type": "text"
      },
      "source": [
        "# Question #2\n",
        "Complete the OpenCL code below to perform matrix multiplcation, you can use pseducode from the slide (Parallal Algorithm). If your code is correct, the value of vector norm must be 0.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEaEVtLVLjK0",
        "colab_type": "code",
        "outputId": "ab5b4004-236b-4f56-cbe0-86ba111f5090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        }
      },
      "source": [
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "import time\n",
        "a_np = np.random.randint(0, high=10, size=[300, 300])\n",
        "b_np = np.random.randint(0, high=10, size=[300, 300])\n",
        "\n",
        "def perform_sequential_multiplication(a_np, b_np):\n",
        "  result = np.zeros_like(a_np)\n",
        "  for i in range(len(a_np)):\n",
        "    for j in range(len(b_np[0])):\n",
        "      for k in range(len(b_np)):\n",
        "        result[i][j] += a_np[i][k] * b_np[k][j]\n",
        "  return result\n",
        "\n",
        "def perform_opencl_multiplication(a_np, b_np):\n",
        "  res_np = np.zeros_like(a_np)\n",
        "  # Your code here\n",
        "  # New_a = a_np.flatten()\n",
        "  # Naw_b = b_np.flatten()\n",
        "  ctx = cl.create_some_context()\n",
        "  queue = cl.CommandQueue(ctx)\n",
        "\n",
        "  mf = cl.mem_flags\n",
        "  a_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=a_np)\n",
        "  b_g = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=b_np)\n",
        "  prg = cl.Program(ctx, \"\"\"\n",
        "  __kernel void multipler(\n",
        "      __global const int *a_g, __global const int *b_g, __global int *res_g)\n",
        "    {\n",
        "      int N = 300;\n",
        "      int col = (get_global_id(0)*2);\n",
        "      int row = (get_global_id(1)*2);\n",
        "      for(int i = 0;i< N*2; i+=2 ){\n",
        "        res_g[row*N+col] += a_g[row*N + i ] * b_g[i*N + col];\n",
        "      }\n",
        " \n",
        "    }\n",
        "  \"\"\").build()\n",
        "\n",
        "  res_g = cl.Buffer(ctx, mf.WRITE_ONLY, a_np.nbytes)\n",
        "  prg.multipler(queue, a_np.shape, None, a_g, b_g, res_g)\n",
        "\n",
        "  cl.enqueue_copy(queue, res_np, res_g)\n",
        "\n",
        "  return res_np\n",
        "print(\"array of a_np\")\n",
        "print(a_np)\n",
        "print (\"-----------------------------------------------------------------------------------------\")\n",
        "print(\"array of b_np\")\n",
        "print(b_np)\n",
        "print (\"-----------------------------------------------------------------------------------------\")\n",
        "start_time = time.time()\n",
        "res_np = perform_sequential_multiplication(a_np, b_np)\n",
        "end_time = time.time()\n",
        "sequential_time = end_time - start_time;\n",
        "print(res_np)\n",
        "print (\"-----------------------------------------------------------------------------------------\")\n",
        "print('Find vector norm to check result:', np.linalg.norm(res_np - np.matmul(a_np, b_np)))\n",
        "print(\"Sequential processing time:\", sequential_time)\n",
        "print (\"-----------------------------------------------------------------------------------------\")\n",
        "start_time = time.time()\n",
        "res_np = perform_opencl_multiplication(a_np, b_np)\n",
        "print(res_np)\n",
        "end_time = time.time()\n",
        "parallel_time = end_time - start_time\n",
        "print (\"-----------------------------------------------------------------------------------------\")\n",
        "print('Find vector norm to check result:', np.linalg.norm(res_np - np.matmul(a_np, b_np)))\n",
        "print(\"Parallel processing time:\", parallel_time)\n",
        "\n",
        "print(\"Speed up:\", sequential_time/parallel_time)\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "array of a_np\n",
            "[[9 7 5 ... 4 7 9]\n",
            " [3 2 4 ... 4 1 7]\n",
            " [0 9 2 ... 9 7 7]\n",
            " ...\n",
            " [1 9 9 ... 2 5 3]\n",
            " [7 0 9 ... 8 8 3]\n",
            " [0 7 7 ... 4 6 2]]\n",
            "-----------------------------------------------------------------------------------------\n",
            "array of b_np\n",
            "[[9 7 0 ... 8 1 3]\n",
            " [6 6 9 ... 1 5 2]\n",
            " [4 9 5 ... 6 9 9]\n",
            " ...\n",
            " [6 5 1 ... 7 7 9]\n",
            " [5 0 4 ... 3 7 4]\n",
            " [4 6 8 ... 6 5 1]]\n",
            "-----------------------------------------------------------------------------------------\n",
            "[[6598 6003 6552 ... 6427 6646 6630]\n",
            " [6423 5853 6307 ... 6498 5790 6190]\n",
            " [6134 5589 5937 ... 6161 5692 5780]\n",
            " ...\n",
            " [6684 5840 6174 ... 6446 6272 6148]\n",
            " [6716 5917 6402 ... 6683 6151 6245]\n",
            " [6809 6114 6695 ... 6681 6413 6495]]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Find vector norm to check result: 0.0\n",
            "Sequential processing time: 29.79215908050537\n",
            "-----------------------------------------------------------------------------------------\n",
            "[[6598 6003 6552 ... 6427 6646 6630]\n",
            " [6423 5853 6307 ... 6498 5790 6190]\n",
            " [6134 5589 5937 ... 6161 5692 5780]\n",
            " ...\n",
            " [6684 5840 6174 ... 6446 6272 6148]\n",
            " [6716 5917 6402 ... 6683 6151 6245]\n",
            " [6809 6114 6695 ... 6681 6413 6495]]\n",
            "-----------------------------------------------------------------------------------------\n",
            "Find vector norm to check result: 0.0\n",
            "Parallel processing time: 0.16135430335998535\n",
            "Speed up: 184.6381438866142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krDqM9UbNVoE",
        "colab_type": "text"
      },
      "source": [
        "# Question #3\n",
        "Q3.1: When the input matrix size is 100 x 100, is the parallel code run faster?\n",
        "\n",
        "Answer: Yes\n",
        "\n",
        "Q3.2: If the parallel code runs faster, what is the speed up?\n",
        "\n",
        "Answer:4.44\n",
        "\n",
        "Q3. What if you increase the matrix size to 200x200, 300x300, 400x400 ... do you see the speed up increased or decreased? \n",
        "\n",
        "Answer:increased\n",
        "\n",
        "Q4: Why?\n",
        "\n",
        "Answer: Because small data with original process faster then small data with parallel process due to transfering data to/from GPU slower then original process.\n",
        "\n",
        "Q6: Again, guess the ratio of paralle portion, please also show your calculation step.\n",
        "\n",
        "Answer: from S = 1/1-P then move P to other side P = S-1/S\n",
        "        then S = 184.63 then P = 0.994 so \n",
        "        the ratio of parallel portion is 99.4 %  "
      ]
    }
  ]
}